\chapter{Sovellus}
\label{ch:sovellus}

Rippikoulujen sisältö pohjautuu rippikoulusuunnitelmaan
\parencite{evlSuuriIhmeRippikoulusuunnitelma2017}, joka määrittää pääraamit
muun muassa sille kaikelle, mitä rippikoulussa käsitellään. Yksi rippikoulun
tärkeistä osaalueista on isoset ja heidän osallistumisensa ohjelman
suunnitteluun ja järjestämiseen. Rippikoulusuunnitelmassa
\parencite{evlSuuriIhmeRippikoulusuunnitelma2017} mainitaankin:

\begin{quotation}
    \noindent Isoset ovat tärkeä osa rippikoulun kokonaisuutta ja myös
    rippikoulun tiimiä. Siksi seurakunnan isostoimintaa ja rippikoulujen
    kokonaisuutta kannattaa suunnitella yhdessä. Isosilla on keskeinen rooli
    rippikoululaisten samastumiskohteina ja ”isosisaruksina”. Rippikoululaiset
    oppivat usein isosilta enemmän kuin ohjaajilta.
\end{quotation}

Rippikoulusuunnitelmassa tuodaan esille se, että eri paikkakunnilla ja eri
seurakunnilla on erilaiset mahdollisuudet järjestää asioita. Tässä työssä
tilannetta katsellaan erityisesti Ruokolahden seurakunnan isosten näkökulmasta.

Ruokolahden seurakunnalla rippikoulu koostuu muun muassa kirkkokäynneistä,
nuortenilloista, etätehtävistä, opetuspäivistä ja lopulta varsinaisesta
leiristä. Vuoden aikana isoskoulutusta käyvät isoset sekä aiempina vuosina
isoskoulutuksen käyneet osallistuvat järjestämään ohjelmaa vuoden aikana
käytäviin nuorteniltoihin sekä ovat avustamassa jumalanpalveluksissa sekä
opetuspäivissä. Nämä ovat yksittäisiä pienempiä asioita, jotka saadaan
yleensä järjestettyä pienemmällä määrällä. Varsinaisella leirillä kuitenkin
tahti on toisenlainen. Parin tunnin ohjelman sijaan leiriläisille luodaan koko
leirin ajaksi ohjelma, joka sisältää toimintaa heräämisestä hiljaisuuteen asti.
Tähän tiiviiseen ohjelmaan pakataan kaikki asiat, joita rippikoululla käydään
läpi. Ohjelmarunko ja opetus on suunniteltu etukäteen, mutta elää tilanteen
mukaan ja harvemmin pysyy alkuperäisessä edes yhtä kokonaista päivää. Ohjelman
ollessa tiivis ja muutosten tullessa tilanteen tarvittaessa erittäin lyhyellä
varoitusajalla ja rippikoulutiimin koostuessa yleensä noin neljästä aikuisesta,
kymmenestä isosesta sekä vierailijoista, kuten kanttorista ja diakonissasta,
on tärkeää, että kaikki ovat ajantasalla milloin mitäkin tapahtuu. Ruokolahden
seurakunnalla tähän käytettiin pitkään ensisijaisesti ja ainuana keinona yhtä
ryhmäkeskustelua, johon kuuluivat kaikki, jotka olivat läsnä leirillä. Leirin
ollessa viikon mittainen, oli viimeisinä päivinä viestien määrä tuhansissa ja
mediaa, kuten kuvia ja pdf:iä, useita satoja. Tällöin sisällön etsintä muuttui
yhä hankalammaksi viikkoa loppuun mennessä ja tiedotetut muutokset olivat
pitkälti muistin varassa.

Tämän työn ohessa on luotu sovellus, joka pyrkii tuomaan helpostusta edellä
kuvattuun tilanteeseen ja keventämään erityisten isosten työkuormaa, mutta
samalla myös ohjaajien. Tulevaisuudeen on mietitty myös mahdollisuutta luoda
mahdollisuus leiriläisille sekä huoltajille nähdä leiriin liittyviä asioita
sovelluksesta. Toistaiseksi sovellus on kuitenkin vain ohjaajien ja isosten
käytössä.

\section{Sovelluksen esittely}

Sovelluksesta löytyy kuvan \ref{fig:isosapp-leirit} mukaisesti kaikki leirit ja
leirien osallistujat, niin ohjaajat, isoset kuin leiriläisetkin. Leirillä
leiriläiset jaetaan leirillä isosryhmiin, jotka saadaan näkyviin leirin
päänykmään kuvassa \ref{fig:isosapp-ryhmat}.

\begin{figure}[h!]
    \centering
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-leirit.png}
        \caption{Seurakunnan näkymä, joka sisältää leirit, ohjaajat ja isoset}
        \label{fig:isosapp-leirit}
    \end{minipage}\qquad
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-ryhmat.png}
        \caption{Leirin päänäkymän ryhmä-osio}
        \label{fig:isosapp-ryhmat}
    \end{minipage}
\end{figure}

Sovellus pohjautuu ensisijaisesti aikatauluun, jonka ympärille kaikki muu
leiriin liittyvä toiminnallisuus on rakennettu. Leirin päänäkymässä kuvassa
\ref{fig:isosapp-nakkilista} on jokaiselle näkyvissä henkilökohtainen
tehtävälista, joka näyttää seuraavan 24 tunnin sisällä olevat ohjelmat, joissa
on vetovastuuna. Samassa näkymässä on myös niin sanottu nakkilista, joka
sisältää päivittäin vaihtuvat roolit isosille. Varsinainen aikataulu löytyy
omasta näkymästä, joka on nähtävissä kuvassa \ref{fig:isosapp-aikataulu}.

\begin{figure}[h!]
    \centering
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-nakkilista.png}
        \caption{Leirin nakkilista ja henkilökohtainen tehtävälista}
        \label{fig:isosapp-nakkilista}
    \end{minipage}\qquad
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-aikataulu.png}
        \caption{Leirin aikataulu ja ohjelmien vastuuhenkilöt}
        \label{fig:isosapp-aikataulu}
    \end{minipage}
\end{figure}

Näiden lisäksi ohjelman suunnittelua helpottamaan on luotu materiaalipankki,
josta löytyy kisoja, leikkejä ja sketsejä sekä listoja lauluista. Aikataulussa
oleviin ohjelmat on mahdollista linkittää suoraan materiaaliin, joten
ohjelmasta pääsee helposti näkemään mm. kilpailun säännöt, kuten kuvassa
\ref{fig:isosapp-materiaalit}. Materiaalin lisäksi ohjelman tekemisessä
tarvitaan välillä yksinkertaisia työkalua, kuten ryhmien arvontaa tai
telepromteria leikkimielisten uutisten lukemiseen. Näitä varten on luotu
kuvassa \ref{fig:isosapp-tyokalut} näkymä työkalu näkymä.

\begin{figure}[h!]
    \centering
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-materiaalit.png}
        \caption{Esimerkki materiaaleihin lisätystä kilpailusta}
        \label{fig:isosapp-materiaalit}
    \end{minipage}\qquad
    \begin{minipage}[b]{.3\textwidth}
        \includegraphics[width=\textwidth]{figures/isosapp-tyokalut.png}
        \caption{Sovelluksen työkalu-näkymä}
        \label{fig:isosapp-tyokalut}
    \end{minipage}
\end{figure}

\clearpage
\section{Kielimallien integrointi osaksi sovellusta}

\begin{wrapfigure}{r}{0.45\textwidth}
    \centering
    \includegraphics[width=0.45\textwidth]{figures/isosapp-tyokalut-tarinan-generointi-1.png}
    \caption{Tarinan luontinäkymä}
    \label{fig:isosapp-tyokalut-tarinan-generointi-1}

    \qquad

    \includegraphics[width=0.45\textwidth]{figures/isosapp-tyokalut-tarinan-generointi-2.png}
    \caption{Sovelluksen työkalu-näkymä}
    \label{fig:isosapp-tyokalut-tarinan-generointi-2}
\end{wrapfigure}

Kielimallit ovat hyviä tuottamaan paljon sisältöä ja nopeasti. On tilanteita,
joissa tällaisesta on hyötyä, vaikka sisältöä ei olisikaan laadullisesti
parasta mahdollista. Yhtenä esimerkkinä tästä on työkalu, jolla saa generoitua
tarinaa. Tätä tarinaa voidaan käyttää pohjana muun muassa sketsien luomisessa.

Sovellukseen on toteutettu kielimalleja hyödyntävä työkalu, jolle saa valittua
käytettävän kielimallin ja annettua ohjeistuksen, mitä tarinan tulisi sisältää,
kuvan \ref{fig:isosapp-tyokalut-tarinan-generointi-1} mukaisesti.
Käyttöliittymä osaa näyttää tarinan vuorosanat sekä toiminnot, kuten kuvassa
\ref{fig:isosapp-tyokalut-tarinan-generointi-2} nähdään. Käyttöliittymä tukee
myös tarinan jatkamista mikäli vain valittulle kielimmallille on toteutettu
kyseinen toiminnallisuus backendin puolelle.

Työkalun lähtökohtana ollut päästä testaamaan useampaa eri kielimallia, joten
toteutuksesta on pyritty tekemään mahdollisimman joustava useammalla eri
kielimallille. Jokaisen kielimallin toteutuksen tulee toteuttaa
\ref{lst:StoryLineService.java} interfacen kaikki metodit, jotta kielimallia
saadaan käytettyä olemassa olevan käyttöliittymän kanssa. Metodit heittää
poikkeuksen, mikäli suoritus ei onnistunut, jolloin käyttöliittymä näyttää
virheen ja mahdollistaa uudelleen yrittämisen.

\clearpage
\begin{lstlisting}[
    basicstyle=\small,
    caption={StoryLineService interface, jonka toteuttamalla kielimallit saadaan },
    label={lst:StoryLineService.java},
    language=java,
]
public interface StoryLineService {

    List<StoryLine> createStoryLines(Story story);
    List<StoryLine> continueStoryLines(Story story);
    void cleanUp(Story story);
}
\end{lstlisting}

\subsection{Gemini toteutus}

Aiemmin kohdassa \ref{lst:GeminiServiceExample.java} esitelty GeminiService
saadaan käyttöön toteuttamalla StorylineService-interfacessa määritellyt
metodit tarinan luomiselle ja jatkamiselle esimerkin
\ref{lst:GeminiService.java} mukaisesti. Geminin kanssa on mahdollista käyttää
ChatSessionia, joka mahdollistaa viestien lähettämisen edestakaisin niin, että
kielimallilla on suoraan käytettävissä aiempi viestittely kontekstina. Tämän
ansiosta tarinaa on helppo jatkaa kunhan aiemmin luotu ChatSession on yhä
käytettävissä.

\begin{lstlisting}[
    basicstyle=\small,
    caption={Esimerkki GeminiServicen StorylineService-interfacen vaatimien metodien toteutuksesta},
    label={lst:GeminiService.java},
    language=java,
]
// Map, johon voidaan tallentaa luodut ChatSessionit myöhempää
// käyttöä varten
private final Map<UUID, ChatSession> chatSessions =
    new ConcurrentHashMap<>();

@Override
public List<StoryLine> createStoryLines(Story story) {
    // Luodaan ilmiintymä mallista ja avataan ChatSession
    GenerativeModel model = new GenerativeModel(
        story.getModelName().getName(),
        vertexAI
    );
    ChatSession chatSession = model.startChat();
    chatSession.withGenerationConfig(createGenerationConfig());

    // Tallennetaan ChatSession ConcurrentHashMap:iin, jotta tarinaa
    // saadaan jatkettua tarvittaessa helposti.
    chatSessions.put(story.getId(), chatSession);

    // Pyydetään luomaan tarina
    GenerateContentResponse response =
        chatSession.sendMessage(createInitializeContent(story));

    // Käsitellään vastaus
    return parseResponse(response);
}

@Override
public List<StoryLine> continueStoryLines(Story story) {
    // Tarkistetaan onko luotua tarinaa mahdollista jatkaa
    if (!chatSessions.containsKey(story.getId()))
        throw new GoneException();

    // Haetaan olemassa oleva ChatSession
    ChatSession chatSession = chatSessions.get(story.getId());

    // Pyydetään jatkamaan tarinaa
    GenerateContentResponse response =
        chatSession.sendMessage("Jatka tarinaa");

    // Käsitellään vastaus
    return parseResponse(response);
}

@Override
public void cleanUp(Story story) {
    // Poistetaan tallessa oleva ChatSession
    chatSessions.remove(story.getId());
}
\end{lstlisting}

Tarinan alustuksessa on annettu kielimallille sanallinen ohjeistus kohdan
\ref{lst:GeminiService.java::createInitializeContent} ja liitteen
\ref{ch:gemini-guide} mukaisesti, jossa on määritelty, missä muodossa vastaus
halutaan ja mitä vastauksen pitäisi sisältää. Ohjeistukseen on liitetty
käyttäjän antama syöte käyttöliittymästä.

\begin{lstlisting}[
    basicstyle=\small,
    caption={Geminin ohjeistuksen luominen},
    label={lst:GeminiService.java::createInitializeContent},
    language=java,
]
private Content createInitializeContent(Story story) {
    String guide = "..."; // Liittestä löytyvä ohjeistus

    // Yhdistetään käyttäjän antama kuvaus ja ohjeistus tulosteesta
    return ContentMaker.fromString(story.getText() + "\n\n" + guide);
}
\end{lstlisting}

Gemini osaa tuottaa sanallisen ohjeistuksen mukaisesti vastauksen suoraan JSON-
muodossa, jolloin se pystytään parsimaan ilman, että vastausta tarvitsee
käsitellä sen enempää. Vastauksen parsiminen saadaan siis toteutettu hyvinkin
yksinkertaisesti esimerkin \ref{lst:GeminiService.java::parseResponse}
mukaisesti.

\begin{lstlisting}[
    basicstyle=\small,
    caption={Geminin vastausten käsittely},
    label={lst:GeminiService.java::parseResponse},
    language=java,
]
private List<StoryLine> parseResponse(GenerateContentResponse response)
    throws JsonProcessingException
{
    // Luetaan vastauksen teksti
    String text = response.getCandidates(0)
        .getContent()
        .getParts(0)
        .getText();

    // Parsitaan luettu json-teksti listaksi StoryLine-ilmiintymiä
    return objectMapper.readValue(text, new TypeReference<>() {});
}
\end{lstlisting}

Toteutuksen jälkeen kielimallia voidaan käyttää tuottamaan kuvassa
\ref{fig:isosapp-tyokalut-tarinan-generointi-2} näkyvä tarina kuvan
\ref{fig:isosapp-tyokalut-tarinan-generointi-1} käyttöliittymän
toiminnallisuudella.

\subsection{PaLM2 toteutus}

Vastaavasti \ref{lst:PaLM2Service.java} kohdassa esitelty PaLM2Service saadaan
toteuttamaan StorylineService-interface esimerkin
\ref{lst:PaLM2Service.java::createStoryLines} mukaisesti. PaLM 2:lle ei ole
tarjolla vastaavaa ChatSessionia, kuin Geminille, joten on sille toteutettu
vain tarinan luonti, muttei mahdollisuutta jatkaa tarinaa.

\begin{lstlisting}[
    basicstyle=\small,
    caption={Esimerkki PaLM2Servicen StorylineService-interfacen metodien toteutuksesta},
    label={lst:PaLM2Service.java::createStoryLines},
    language=java,
]
@Override
public List<StoryLine> createStoryLines(Story story) {
    // Tehdään pyyntö kielimallille
    PredictResponse predictResponse = vertexAI
        .getPredictionServiceClient()
        .predict(PredictRequest.newBuilder()
            .setEndpoint(
                getEndpointName(story.getModelName().getName())
                .toString())
            .addInstances(getPrompt(generatePrompt(story)))
            .setParameters(getParameters())
            .build());

    // Käsitellään vastaus
    return parseResponse(response);
}
\end{lstlisting}

PaLM2-kielimallille on luotu vastaava ohjeistuis kuin Geminille, jossa
määritellään minkälainen vastaus kielimallin tulisi tuottaa ja kielimallille
annetaan käyttäjän antama syöte. Ohjeistuksen toteutus on nähtävissä kohdassa
\ref{lst:PaLM2Service.java::generatePrompt} ja koko ohjeistus liitteessä \ref{ch:palm2-guide}.

\begin{lstlisting}[
    basicstyle=\small,
    caption={PaLM2 ohjeistuksen luonti},
    label={lst:PaLM2Service.java::generatePrompt},
    language=java,
]
private String generatePrompt(Story story) {
    String guide = "..."; // Liitteestä löytyvä ohjeistus

    // Yhdistetään käyttäjän antama syöte ja ohjeistus
    return story.getText() + "\n\n" + guide;
}

// Apufunktio ohjeistuksen muuttamiseen kielimallin haluamaan muotoon
private com.google.protobuf.Value getPrompt(String prompt) throws
    InvalidProtocolBufferException, JsonProcessingException
{
    Map<String, Object> instance = new HashMap<>();
    instance.put("prompt", prompt);
    return convertMapToValue(instance);
}
\end{lstlisting}

PaLM2:sta ohjeistaessa sanallisesti, että tuloksen tulee olla JSON-muodossa,
tulee tuloste Markdownin tukemassa JSON-muodossa, jossa varsinanen JSON osuus
on ympäritöity JSON-koodiosiota tarkoittavilla merkinnöillä. Jotta tulos
saadaan käsitelty, tulee vastauksesta saada nämä pois. Tämä saadaan toteutettua
esimerkin \ref{lst:PaLM2Service.java::parseResponse} mukaisesti.

\begin{lstlisting}[
    basicstyle=\small,
    caption={PaLM2 vastauksen käsittely},
    label={lst:PaLM2Service.java::parseResponse},
    language=java,
]
private List<StoryLine> parseResponse(PredictResponse response)
    throws JsonProcessingException
{
    String json = response
        .getPredictions(0)
        .getStructValue()
        .getFieldsOrThrow("content")
        .getStringValue()
        .replaceFirst("```json\n", "")
        .replaceFirst("```", "");

    return objectMapper.readValue(json, new TypeReference<>() {});
}
\end{lstlisting}

\subsection{Llama 3 toteutus}

Kun Llama 3:sta käytetään VertexAI:n tarjoaman kirjaston kautta, tukee se
samoja toimintoja, kuin mitä on käytetty Geminin toteutuksessa. Toteutus
saadaan tällöin tehtyä samanlaisena kuin Geminillä kohdassa
\ref{lst:GeminiService.java}.

Kielimallille annettava ohjeistus eroaa kuitenkin siitä, mitä Geminille
annetaan. Ohjeistus saadaan luotua vastaavasti kuin Geminille kohdassa
\ref{lst:GeminiService.java::createInitializeContent}, mutta ohjeistuksena
annettava teksti on liitteessä \ref{ch:llama3-guide}. Ohjeistus on vastaava
kuin PaLM2:lla, mutta kielimallille tuli erikseen sanoa, että tulosteessa ei
saa olla muuta kuin JSON-vastaus, jotta kielimalli jätti ylimääräisen
tulosteen pois ja tuotti vain halutun tuloksen.

\subsection{xAI:n toteutus}

XAI:n rajapinnan dokumentaatiossa on määritelty 'response\_format'-kenttä, mutta
kyseiselle kentälle ei ole määritelty tyyppiä \parencite{xAIDocsEndpoints}.
Mahdollinen formaatti kyseiselle kentälle löydetään Githubissa olevasta
issuesta \parencite{githubBerriAIlitellmIssues6610}, jossa ongelmana on se,
ettei vastauksen formatointi ole tuettu sillä hetkellä. Testaamalla samalla
formaatilla saamme itsekkin vastauksena kohdassa \ref{lst:xai-bad-request.json}
näkyvän virheviestin ettei ainakaan kyseinen formatointi ole käytössä.

\begin{lstlisting}[
    basicstyle=\small,
    caption={XAI rajapinnan palauttama vastaus, kun yritetään määrittää 'response\_format'-kenttä},
    label={lst:xai-bad-request.json},
]
{
    "code":"Client specified an invalid argument",
    "error":"The model does not support formatted output but some
      have been specified in the request."
}
\end{lstlisting}

Vaikkei rajapinta suoraan vaikuta tukevan vastauksen muotoilua, voidaan ohjeet
muotoiluun antaa kirjallisesti. Alustamalla keskustelu system-roolilta
tulevalla viestillä:

\begin{quotation}
    \noindent Olet käsikirjoittaja. Luot tarinan käyttäjän antaman syötteen
    perusteella.

    \noindent Vastauksesi tulee olla JSON-muodossa oleva lista, joka koostuu
    olioista, joilla on kolme attribuuttia: type, target ja content. Type voi
    olla joko `ACTION` tai `TALK` riippuen siitä, onko kyseessä jotakin mitä
    tapahtuu vai jotain mitä joku sanoo. Target kuvastaa sitä kuka tekee tai
    kuka sanoo. Content kuvastaa sitä mitä tapahtuu tai sanotaan.
\end{quotation}

saadaan vastaukset halutussa JSON-muodossa, jonka myötä saadaan viesti
parsittua StoryLineService-interfacen metodien vastauksien haluamaan
muotoon antamalla vastaus suoraan JSON-parserille kohdan
\ref{lst:XAIService.java::parseResponse} mukaisesti.

\begin{lstlisting}[
    basicstyle=\small,
    caption={XAI rajapinnan palauttaman vastauksen parsiminen haluttuun muotoon},
    label={lst:XAIService.java::parseResponse},
    language=java,
]
private List<StoryLine> parseResponse(Message message)
    throws IOException
{
    // Luetaan viestin sisältö ja poistetaan ylimääräinen muotoilu
    String json = message.content()
        .replaceFirst("```json\n", "")
        .replaceFirst("```", "");

    // Luetaan tekstimuodossa oleva json listaksi StoryLine-olioita
    return objectMapper.readValue(json, new TypeReference<>() {});
}
\end{lstlisting}

Käytettävä rajapinta päätepiste pohjautuu alunperinkin siihen, että sinne
lähetetään lista viesteistä. Tätä hyödyntämällä pystymme toteuttamaan
toiminnallisuuden tarinan jatkamiseen. Pitämällä kirjaa aiemmista viesteistä
voimme tarinan jatkamisessa yksinkertaisesti hakea vanhat viestit ja pyytää
jatkamaan tarinaa kuten kohdassa \ref{lst:XAIService.java::continueStoryLines}
olevassa toteutuksessa on tehty.

\begin{lstlisting}[
    basicstyle=\small,
    caption={XAI rajapinnan palauttaman vastauksen parsiminen haluttuun muotoon},
    label={lst:XAIService.java::continueStoryLines},
    language=java,
]
public List<StoryLine> continueStoryLines(Story story) {
    // Haetaan keskustelun vanhat viestit
    List<Message> messages = chats.get(story.getId());

    // Tarkistetaan ettei tarina kasva liian pitkäksi
    if (story.getLines().size() > 50 || messages.size() > 10)
        throw new BadRequestException("Tarina on liian pitkä!");

    // Lisätään käyttäjän pyyntö jatkaa tarinaa
    messages.add(new Message("user", "Jatka tarinaa"));

    // tehdään pyyntö
    // parsitaan vastaus
    // palautetaan uudet rivit
}
\end{lstlisting}

\section{Kielimallien toimivuuden arviointia}
